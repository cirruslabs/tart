{"version": "https://jsonfeed.org/version/1.1", "title": "Tart Virtualization", "home_page_url": "https://tart.run/", "feed_url": "https://tart.run/feed_json_updated.json", "description": "Tart is a virtualization toolset to build, run and manage macOS and Linux virtual machines (VMs) on Apple Silicon.\n", "icon": null, "authors": [{"name": "Cirrus Labs"}], "language": "en", "items": [{"id": "https://tart.run/blog/2023/02/11/changing-tart-license/", "url": "https://tart.run/blog/2023/02/11/changing-tart-license/", "title": "Changing Tart License", "content_html": "<h1 id=\"changing-tart-license\">Changing Tart License<a class=\"headerlink\" href=\"#changing-tart-license\" title=\"Permanent link\">&para;</a></h1>\n<p><strong>TLDR:</strong> We are transitioning Tart's licensing from AGPL-3.0 to <a href=\"https://fair.io/\">Fair Source 100</a>. This change will\npermit unlimited installations on personal computers, but organizations that exceed a certain number of server\ninstallations utilizing 100 CPU cores will be required to obtain a paid license.</p>\n<h2 id=\"background\">Background<a class=\"headerlink\" href=\"#background\" title=\"Permanent link\">&para;</a></h2>\n<p>Exactly a year ago on February 11<sup>th</sup> 2022 we started working on Tart \u2013 a tiny CLI to run macOS virtual machines on Apple Silicon.\nThree months later we successfully started using Tart in our own production system and decided to share Tart with everyone.</p>\n<p><img src=\"https://github.com/cirruslabs/tart/raw/main/Resources/TartSocial.png\"/></p>\n<p>The goal was to establish a community of users and contributors to transform Tart from a small CLI to a robust tool\nfor various scenarios. <strong>Unfortunately, we were not successful in attracting a significant number of contributors.</strong>\nIt's important to note that we did have seven individuals who contributed to the development of Tart to the best of\ntheir abilities. However, one of the challenges of contributing to Tart is that the skill set required for a contribution\nis vastly different from the skill set typically possessed by regular Tart users in their daily work. Specifically,\na contributor needs to have knowledge of the Swift programming language, as well as a background in operating systems\nand network stack. This is the reason why <strong>98.8% of the code and all the major features were contributed by Cirrus Labs engineers.</strong></p>\n<!-- more -->\n\n<p>Tart is experiencing significant success among users and has seen widespread adoption for various applications.\nThe latest macOS Ventura virtual machine image has been downloaded over 27,000 times! We are continually receiving\nfeedback from an increasing number of users who are utilizing Tart in ways we had not initially anticipated. However,\nwith a growing user base comes a rise in requests for new features and enhancements. It can be challenging to justify\ndedicating our engineering resources to meeting these demands when they do not align with the needs of our company, Cirrus Labs.\nAs a small, self-funded organization, our priority is to provide for our employees and their families along with developing great products.</p>\n<p>In addition, the <strong>decision to use AGPL-3.0 as the license for Tart was not thoroughly considered at the time of its release.</strong>\nThe choice was made because many companies that were commercializing their products had recently switched to the AGPL license.\nHowever, AGPL has a reputation for being viral, open to interpretation, and not in line with current standards. Additionally,\nmany organizations have policies against using any AGPL-licensed software in their stacks, which has limited Tart's potential\nfor wider adoption. See <a href=\"https://opensource.google/documentation/reference/using/agpl-policy\">Google's AGPL policy</a>, for example.</p>\n<p>In order to ensure Tart's long-term viability and to allow us to allocate engineering resources towards further improving Tart,\nwe plan to transition to a licensing model that includes a nominal fee for companies that reach a substantial level of usage.</p>\n<h2 id=\"what-is-changing\">What is changing<a class=\"headerlink\" href=\"#what-is-changing\" title=\"Permanent link\">&para;</a></h2>\n<p>In the near future, we are set to launch the first version of Orchard for Tart, a tool that facilitates the coordination\nof Tart virtual machines on a cluster of Apple Silicon servers. Concurrently, we will also release version 1.0.0 of Tart,\nwhich will establish a stable API and offer long-term support under a new Fair Source 100 license.</p>\n<p>The Fair Source 100 license for Tart means that once a certain threshold of server installations utilizing 100 CPU cores\nis exceeded, a paid license will be required. A \"server installation\" refers to the installation of Tart on a physical\ndevice without a physical display connected. For example, a Mac Mini with a HDMI Dummy Plug is considered a server,\nbut a Mac Mini on a desk with a connected physical display is considered a personal computer. <strong>Usage on personal computers\nand before reaching the 100 CPU cores limit is royalty-free and does not have the viral properties of AGPL.</strong></p>\n<div class=\"admonition note\">\n<p class=\"admonition-title\">Pricing update</p>\n<p>This post announced Tart licensing in February 2023 and originally listed monthly prices.\nPricing has since changed to yearly billing. See <a href=\"../../../../../licensing/#license-tiers\">Licensing and Support</a> for the latest terms.</p>\n</div>\n<p>When an organization surpasses the 100 CPU cores limit, they will be required to obtain a <a href=\"../../../../../licensing/#license-tiers\">Gold Tier License</a>,\nwhich costs $12,000 per year. Upon reaching a limit of 500 CPU cores, a <a href=\"../../../../../licensing/#license-tiers\">Platinum Tier License</a>\n($36,000 per year) will be required, and for organizations that exceed 3000 CPU cores, a custom <a href=\"../../../../../licensing/#license-tiers\">Diamond Tier License</a>\n($12 per core per year) will be necessary. <strong>All paid license tiers will include priority feature development and SLAs on support with urgent issues.</strong></p>\n<h2 id=\"have-we-considered-alternatives\">Have we considered alternatives?<a class=\"headerlink\" href=\"#have-we-considered-alternatives\" title=\"Permanent link\">&para;</a></h2>\n<p>We have evaluated other options. Initially, we reached out to some of our largest users and asked them to consider\nsponsoring the development of features that they were interested in. However, we received no response or were eventually\nignored. Another option we considered was using the open core model and developing enterprise-specific features. However,\nthis approach is not addressing concerns related to the viral nature of AGPL for non-enterprise users. Ultimately,\nwe concluded that transitioning to a source-available model with a mandatory paid licensing is fair, as the licensing fees\nare relatively insignificant for companies that reach a significant level of usage.</p>\n<p>If you have any questions or concerns, please feel free to reach out to <a href=\"mailto:licensing@cirruslabs.org\">licensing@cirruslabs.org</a>.\nIf the new licensing model is not suitable for your organization, you are welcome to continue using the AGPL version of Tart,\nbut please ensure it is not used in a non-AGPL environment.</p>", "image": "https://tart.run/assets/images/social/blog/2023/02/11/changing-tart-license.png", "date_modified": "2026-02-13T15:46:01+00:00", "date_published": "2023-02-11T00:00:00+00:00", "authors": [{"name": "Fedor Korotkov"}], "tags": null}, {"id": "https://tart.run/blog/2025/10/27/press-release-cirrus-labs-successfully-enforces-its-fair-source-license/", "url": "https://tart.run/blog/2025/10/27/press-release-cirrus-labs-successfully-enforces-its-fair-source-license/", "title": "Press Release: Cirrus Labs Successfully Enforces Its Fair Source License", "content_html": "<h1 id=\"press-release-cirrus-labs-successfully-enforces-its-fair-source-license\">Press Release: Cirrus Labs Successfully Enforces Its Fair Source License<a class=\"headerlink\" href=\"#press-release-cirrus-labs-successfully-enforces-its-fair-source-license\" title=\"Permanent link\">&para;</a></h1>\n<p><strong>New York City, NY \u2013 October 27<sup>th</sup>, 2025 \u2013 Cirrus Labs, Inc.</strong>, a leading provider of platforms for digital transformation, today announced that it has reached a settlement agreement regarding a violation of its Fair Source License.</p>\n<!-- more -->\n\n<p>Cirrus Labs makes its Tart Virtualization Toolset, a leading virtualization toolset to build, run and manage macOS and Linux virtual machines (VMs) on Apple Silicon,\nfreely available on GitHub under the Fair Source License, a source-available license. Tart is used by tens of thousands of engineers at no charge within its generous free\u2011use limits.\nMany large enterprises that need to exceed those limits support continued development through paid licenses. Cirrus Labs also uses Tart to power <a href=\"https://cirrus-runners.app/\">Cirrus Runners</a>\n\u2014 a drop\u2011in replacement for macOS and Linux runners for GitHub Actions \u2014 offered at a fixed monthly price for unlimited usage.</p>\n<p>Cirrus Labs discovered that, <strong>despite a prior licensing request that was declined due to a conflict of interest</strong>, another company used Tart in a manner that exceeded the license\u2019s free\u2011use limits,\nin order to create a competing product.</p>\n<p>After several months of negotiations, the matter was settled and a settlement payment to Cirrus Labs was agreed upon.</p>\n<div class=\"admonition quote\">\n<p class=\"admonition-title\">Comment by Fedor Korotkov, CEO of Cirrus Labs</p>\n<p>As a company we embrace healthy competition that ultimately benefits the end user. Most of our users have no trouble complying with our license,\nand even when they need something more than our free use limits, we can almost always grant them a license that fits their needs. <strong>This was an exceptional case.</strong>\nWe are pleased to have reached this settlement, which validates our source-available licensing strategy and reinforces our commitment to protecting our company and serving our community.</p>\n</div>\n<p>Cirrus Labs was represented in this matter by <a href=\"https://byronraphael.com/attorneys/jordan-raphael/\">Jordan Raphael</a> of Byron Raphael LLP, a boutique intellectual property law firm,\nand <a href=\"https://www.techlawpartners.com/heather\">Heather Meeker</a>, a well-known specialist in open source and source available licensing.</p>\n<p>The specific financial terms of the settlement and the identity of the counterparty remain confidential.</p>\n<p><strong>About Cirrus Labs:</strong> Cirrus Labs, Inc. is a bootstrapped developer-infrastructure company founded in 2017. Our offerings among others include Tart and Cirrus Runners,\nand our software is used by teams at category-leading companies including Atlassian, Figma, Zendesk, Sentry and many more.</p>\n<p>Learn more at <a href=\"https://tart.run/\">https://tart.run/</a> and <a href=\"https://cirrus-runners.app/\">https://cirrus-runners.app/</a>.</p>\n<p><strong>Contact:</strong> <a href=\"mailto:hello@cirruslabs.org\">hello@cirruslabs.org</a></p>", "image": "https://tart.run/assets/images/social/blog/2025/10/27/press-release-cirrus-labs-successfully-enforces-its-fair-source-license.png", "date_modified": "2025-10-27T16:04:35+00:00", "date_published": "2025-10-27T00:00:00+00:00", "authors": [{"name": "Fedor Korotkov"}], "tags": null}, {"id": "https://tart.run/blog/2023/04/25/announcing-orchard-orchestration-for-managing-macos-virtual-machines-at-scale/", "url": "https://tart.run/blog/2023/04/25/announcing-orchard-orchestration-for-managing-macos-virtual-machines-at-scale/", "title": "Announcing Orchard orchestration for managing macOS virtual machines at scale", "content_html": "<h1 id=\"announcing-orchard-orchestration-for-managing-macos-virtual-machines-at-scale\">Announcing Orchard orchestration for managing macOS virtual machines at scale<a class=\"headerlink\" href=\"#announcing-orchard-orchestration-for-managing-macos-virtual-machines-at-scale\" title=\"Permanent link\">&para;</a></h1>\n<p>Today we are happy to announce general availability of Orchard \u2013 our new orchestrator to manage Tart virtual machines at scale.\nIn this post we\u2019ll cover the motivation behind creating yet another orchestrator and why we didn\u2019t go with Kubernetes or Nomad integration.</p>\n<h2 id=\"what-problem-are-we-trying-to-solve\">What problem are we trying to solve?<a class=\"headerlink\" href=\"#what-problem-are-we-trying-to-solve\" title=\"Permanent link\">&para;</a></h2>\n<p>After releasing Tart we pretty quickly started getting requests about managing macOS virtual machines on a cluster of\nApple Silicon machines rather than just a single host which only allows a maximum of two virtual machines at a time.\nBy the end of 2022 the requests reached a tipping point, and we started planning.</p>\n<!-- more -->\n\n<p>First, we established some constraints about the end users and potential workload our solution should handle.\nRunning macOS or Linux virtual machines on Apple Silicon is a very niche use case. These VMs are either used in\nautomation solutions like CI/CD or for managing remote desktop environments. In this case <strong>we are aiming to manage\nonly thousands of virtual machines and not millions</strong>.</p>\n<p>Second, <strong>operators of such solutions won\u2019t have experience of operating Kubernetes or Nomad</strong>. Operators will most likely\ncome with experience of using such systems but not managing them. And again, having built-in things like RBAC and\nability to scale to millions were appealing but it seemed like it would be a solution for a few rather than a solution\nfor everybody to use. Additionally Orchard should provide <strong>first class support for accessing virtual machines over SSH/VNC</strong>\nand support script execution.</p>\n<p>By that time, the idea of building a simple opinionated orchestrator got more and more appealing. Plus we kind of already did it\nfor <a href=\"https://cirrus-ci.org/guide/persistent-workers/\">Cirrus CI\u2019s persistent workers</a> feature.</p>\n<h2 id=\"technical-constraints\">Technical constraints<a class=\"headerlink\" href=\"#technical-constraints\" title=\"Permanent link\">&para;</a></h2>\n<p>With the UX constraints and expectations in place we started thinking about architecture for the orchestrator that we\nstarted calling <strong>Orchard</strong>.</p>\n<script src=\"https://unpkg.com/@dotlottie/player-component@latest/dist/dotlottie-player.js\"></script>\n<p><dotlottie-player\nsrc=\"/assets/animations/Orchard.lottie\"\nmode=\"normal\"\nstyle=\"width: 100%; height: 360px; margin: auto; background-color: rgb(5 62 94)\"\nautoplay\nloop\n/></p>\n<p>Since Orchard will manage a maximum of a couple thousands virtual machines and not millions we <strong>decided to not think much\nabout horizontal scalability.</strong> Just a single instance of Orchard controller should be enough if it can restart quickly and\npersist state between restarts.</p>\n<p><strong>Orchard should be secure by default</strong>. All the communication between a controller and workers should be secure.\nAll external API requests to Orchard controller should be authorized.</p>\n<p>During development it\u2019s crucial to have a quick feedback cycle. <strong>It should be extremely easy to run Orchard in development</strong>.\nConfiguring a production cluster should be also easy for novice operators.</p>\n<h2 id=\"high-level-implementation-details\">High-level implementation details<a class=\"headerlink\" href=\"#high-level-implementation-details\" title=\"Permanent link\">&para;</a></h2>\n<p>Cirrus Labs started as a predominantly Kotlin shop with a little Go. But over the years we gradually moved a lot of things to Go.\nWe love the expressibility of Kotlin as a language but the ecosystem for writing system utilities and services is superb in Go.</p>\n<p>Orchard is a single Go project that implements both controller server interface and worker client logic in a single repository.\nThis simplifies code sharing and testability of the both components and allows to change them in a single pull request.</p>\n<p>Another benefit is that Orchard can be distributed as a single binary. We intend to run Orchard controller on a single host.\nData model for the orchestration didn\u2019t look complex as well. These observations lead us to exploring the use of an embedded database.\nJust imagine! <strong>Orchard can be distributed as a single binary with no external dependencies on any database or runtime!</strong></p>\n<p>And we did exactly that! Orchard is distributed as a single binary that can be run in \u201ccontroller\u201d mode on a Linux/macOS host and\nin \u201cworker\u201d mode on macOS hosts. Orchard controller is using extremely fast <a href=\"https://dgraph.io/docs/badger/\">BadgerDB</a> key-value storage to persist data.</p>\n<h2 id=\"conclusion\">Conclusion<a class=\"headerlink\" href=\"#conclusion\" title=\"Permanent link\">&para;</a></h2>\n<p>Please give <a href=\"https://github.com/cirruslabs/orchard\">Orchard</a> a try! To run it locally in development mode on any Apple Silicon device\nplease run the following command:</p>\n<div class=\"highlight\"><pre><span></span><code><a id=\"__codelineno-0-1\" name=\"__codelineno-0-1\" href=\"#__codelineno-0-1\"></a>brew<span class=\"w\"> </span>install<span class=\"w\"> </span>cirruslabs/cli/orchard\n<a id=\"__codelineno-0-2\" name=\"__codelineno-0-2\" href=\"#__codelineno-0-2\"></a>orchard<span class=\"w\"> </span>dev\n</code></pre></div>\n<p>This will launch a development cluster with a single worker on your machine. Refer to <a href=\"https://github.com/cirruslabs/orchard#creating-virtual-machines\">Orchard documentation</a>\non how to create your first virtual machine and access it.</p>\n<p>In a <a href=\"../../28/ssh-over-grpc-or-how-orchard-simplifies-accessing-vms-in-private-networks/\">separate blog post</a>\nwe\u2019ll cover how Orchard implements seamless SSH access over a gRPC connection. Stay tuned and please don\u2019t hesitate to\n<a href=\"https://github.com/cirruslabs/orchard/discussions/landing\">reach out</a>! </p>", "image": "https://tart.run/assets/images/social/blog/2023/04/25/announcing-orchard-orchestration-for-managing-macos-virtual-machines-at-scale.png", "date_modified": "2025-09-22T20:02:39+00:00", "date_published": "2023-04-25T00:00:00+00:00", "authors": [{"name": "Fedor Korotkov"}], "tags": null}, {"id": "https://tart.run/blog/2023/04/28/ssh-over-grpc-or-how-orchard-simplifies-accessing-vms-in-private-networks/", "url": "https://tart.run/blog/2023/04/28/ssh-over-grpc-or-how-orchard-simplifies-accessing-vms-in-private-networks/", "title": "SSH over gRPC or how Orchard simplifies accessing VMs in private networks", "content_html": "<h1 id=\"ssh-over-grpc-or-how-orchard-simplifies-accessing-vms-in-private-networks\">SSH over gRPC or how Orchard simplifies accessing VMs in private networks<a class=\"headerlink\" href=\"#ssh-over-grpc-or-how-orchard-simplifies-accessing-vms-in-private-networks\" title=\"Permanent link\">&para;</a></h1>\n<p>We started developing <a href=\"https://github.com/cirruslabs/orchard\">Orchard</a>, an orchestrator for <a href=\"https://tart.run/\">Tart</a>, with the requirement that it should allow users to access virtual machines running on worker nodes in private networks that users might not have access to.</p>\n<p>At the same time, we wanted to enable users to access VMs on these remote workers just as easily as they\u2019d access network services on their local Tart VMs.</p>\n<p>While these features sound great on paper, they pose a technical problem: how do we connect to the remote workers, let alone VMs running on these workers, if we can\u2019t assume that these workers will be easily reachable? And how do we establish an SSH connection with a VM running on a remote worker through all these hoops?</p>\n<!-- more -->\n\n<h2 id=\"implementing-port-forwarding-grpc-to-the-rescue\">Implementing port forwarding: gRPC to the rescue<a class=\"headerlink\" href=\"#implementing-port-forwarding-grpc-to-the-rescue\" title=\"Permanent link\">&para;</a></h2>\n<p>We need to keep a full-duplex connection with the controller for the port-forwarding to work, and the two obvious protocol options are:</p>\n<ul>\n<li>WebSocket API through a new controller\u2019s REST API endpoint</li>\n<li>gRPC using <code>Content-Type</code> differentiation</li>\n</ul>\n<p>We\u2019ve chosen the gRPC for controller \u2194\ufe0e worker connection, simply because it requires less code on our side and it will only be used internally, which means we don\u2019t need to document it as extensively as our REST API. In essence, port forwarding is streaming of bytes of a connection in both ways, so gRPC streams looked like a natural solution. The resulting protocol is dead simple:</p>\n<div class=\"highlight\"><pre><span></span><code><a id=\"__codelineno-0-1\" name=\"__codelineno-0-1\" href=\"#__codelineno-0-1\"></a><span class=\"kd\">service</span><span class=\"w\"> </span><span class=\"n\">Controller</span><span class=\"w\"> </span><span class=\"p\">{</span>\n<a id=\"__codelineno-0-2\" name=\"__codelineno-0-2\" href=\"#__codelineno-0-2\"></a><span class=\"w\">  </span><span class=\"k\">rpc</span><span class=\"w\"> </span><span class=\"n\">Watch</span><span class=\"p\">(</span><span class=\"n\">google.protobuf.Empty</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"k\">returns</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"n\">stream</span><span class=\"w\"> </span><span class=\"n\">WatchInstruction</span><span class=\"p\">);</span>\n<a id=\"__codelineno-0-3\" name=\"__codelineno-0-3\" href=\"#__codelineno-0-3\"></a>\n<a id=\"__codelineno-0-4\" name=\"__codelineno-0-4\" href=\"#__codelineno-0-4\"></a><span class=\"w\">  </span><span class=\"k\">rpc</span><span class=\"w\"> </span><span class=\"n\">PortForward</span><span class=\"p\">(</span><span class=\"n\">stream</span><span class=\"w\"> </span><span class=\"n\">PortForwardData</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"k\">returns</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"n\">stream</span><span class=\"w\"> </span><span class=\"n\">PortForwardData</span><span class=\"p\">);</span>\n<a id=\"__codelineno-0-5\" name=\"__codelineno-0-5\" href=\"#__codelineno-0-5\"></a><span class=\"p\">}</span>\n<a id=\"__codelineno-0-6\" name=\"__codelineno-0-6\" href=\"#__codelineno-0-6\"></a>\n<a id=\"__codelineno-0-7\" name=\"__codelineno-0-7\" href=\"#__codelineno-0-7\"></a><span class=\"kd\">message</span><span class=\"w\"> </span><span class=\"nc\">WatchInstruction</span><span class=\"w\"> </span><span class=\"p\">{</span>\n<a id=\"__codelineno-0-8\" name=\"__codelineno-0-8\" href=\"#__codelineno-0-8\"></a><span class=\"w\">  </span><span class=\"kd\">message</span><span class=\"w\"> </span><span class=\"nc\">PortForward</span><span class=\"w\"> </span><span class=\"p\">{</span>\n<a id=\"__codelineno-0-9\" name=\"__codelineno-0-9\" href=\"#__codelineno-0-9\"></a><span class=\"w\">    </span><span class=\"kt\">string</span><span class=\"w\"> </span><span class=\"na\">session</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"p\">;</span>\n<a id=\"__codelineno-0-10\" name=\"__codelineno-0-10\" href=\"#__codelineno-0-10\"></a><span class=\"w\">    </span><span class=\"kt\">string</span><span class=\"w\"> </span><span class=\"na\">vm_uid</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"p\">;</span>\n<a id=\"__codelineno-0-11\" name=\"__codelineno-0-11\" href=\"#__codelineno-0-11\"></a><span class=\"w\">    </span><span class=\"kt\">uint32</span><span class=\"w\"> </span><span class=\"na\">vm_port</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"p\">;</span>\n<a id=\"__codelineno-0-12\" name=\"__codelineno-0-12\" href=\"#__codelineno-0-12\"></a><span class=\"w\">  </span><span class=\"p\">}</span>\n<a id=\"__codelineno-0-13\" name=\"__codelineno-0-13\" href=\"#__codelineno-0-13\"></a>\n<a id=\"__codelineno-0-14\" name=\"__codelineno-0-14\" href=\"#__codelineno-0-14\"></a><span class=\"w\">  </span><span class=\"k\">oneof</span><span class=\"w\"> </span><span class=\"n\">action</span><span class=\"w\"> </span><span class=\"p\">{</span>\n<a id=\"__codelineno-0-15\" name=\"__codelineno-0-15\" href=\"#__codelineno-0-15\"></a><span class=\"w\">    </span><span class=\"n\">PortForward</span><span class=\"w\"> </span><span class=\"na\">port_forward_action</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"p\">;</span>\n<a id=\"__codelineno-0-16\" name=\"__codelineno-0-16\" href=\"#__codelineno-0-16\"></a><span class=\"w\">  </span><span class=\"p\">}</span>\n<a id=\"__codelineno-0-17\" name=\"__codelineno-0-17\" href=\"#__codelineno-0-17\"></a><span class=\"p\">}</span>\n<a id=\"__codelineno-0-18\" name=\"__codelineno-0-18\" href=\"#__codelineno-0-18\"></a>\n<a id=\"__codelineno-0-19\" name=\"__codelineno-0-19\" href=\"#__codelineno-0-19\"></a><span class=\"kd\">message</span><span class=\"w\"> </span><span class=\"nc\">PortForwardData</span><span class=\"w\"> </span><span class=\"p\">{</span>\n<a id=\"__codelineno-0-20\" name=\"__codelineno-0-20\" href=\"#__codelineno-0-20\"></a><span class=\"w\">  </span><span class=\"kt\">bytes</span><span class=\"w\"> </span><span class=\"na\">data</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"p\">;</span>\n<a id=\"__codelineno-0-21\" name=\"__codelineno-0-21\" href=\"#__codelineno-0-21\"></a><span class=\"p\">}</span>\n</code></pre></div>\n<p>On bootstrap, each Orchard worker establishes a <code>Watch()</code> RPC stream and waits for the <code>PortForward</code> instruction from the controller indefinitely. This long-running session might be used not just for port-forwarding, but for notifying the workers about changed resources, which results in workers picking up your VM for execution instantly.</p>\n<p>Once <code>PortForward</code> instruction is received, the worker connects to the specified VM and port locally and opens a new <code>PortForward()</code> RPC stream with the controller, carrying the unique <code>session</code> identifier in the gRPC metadata to help distinguish several port forwarding requests.</p>\n<p>We\u2019re using a pretty ingenious <a href=\"https://github.com/mitchellh/go-grpc-net-conn\">Golang package that turns any gRPC stream into a <code>net.Conn</code></a>. This allows us to abstract from the gRPC details and simply proxy two <code>net.Conns</code>, thus providing the port forwarding functionality.</p>\n<p>We\u2019ve also initially considered using <a href=\"https://github.com/hashicorp/yamux\">Yamux</a> to only keep a single connection with each worker, however, that involves the burden of dealing with flow control and potential implementation bugs associated with it, so we\u2019ve decided to simply open an additional connection for each port forwarding session and let the OS deal with it.</p>\n<h2 id=\"building-on-top-of-the-port-forwarding\">Building on top of the port-forwarding<a class=\"headerlink\" href=\"#building-on-top-of-the-port-forwarding\" title=\"Permanent link\">&para;</a></h2>\n<p>First of all, we\u2019ve made the new port-forwarding functionality available for integrations via the Orchard\u2019s REST API:</p>\n<p><img alt=\"OpenAPI documentation for Orchard's port-forwarding endpoint\" src=\"../../../../../assets/images/orchard-port-forwarding-api.png\" /></p>\n<p>All you need is to use a WebSocket client when accessing this endpoint to make it work.</p>\n<p>Secondly, we\u2019ve exposed three commands in the Orchard CLI that all use this endpoint:</p>\n<h3 id=\"orchard-port-forward\"><code>orchard port-forward</code><a class=\"headerlink\" href=\"#orchard-port-forward\" title=\"Permanent link\">&para;</a></h3>\n<p>Opens a TCP port locally and forwards everything sent to it to the specified VM (and vice versa).</p>\n<p>For example, <code>orchard port-forward vm sonoma-builder 2222:22</code> will forward traffic from the local TCP port <code>2222</code> to the <code>ventura-builder</code> VM\u2019s TCP port <code>22</code>.</p>\n<h3 id=\"orchard-ssh\"><code>orchard ssh</code><a class=\"headerlink\" href=\"#orchard-ssh\" title=\"Permanent link\">&para;</a></h3>\n<p>Connects to the specified VM on the default SSH port <code>22</code>, optionally only launching a command (if specified), similarly to what the official OpenSSH client does.</p>\n<p>For example, <code>orchard ssh vm sonoma-builder</code> will open an interactive session with the <code>ventura-builder</code> VM.</p>\n<p>You can also send local scripts for execution by utilizing redirection:</p>\n<div class=\"highlight\"><pre><span></span><code><a id=\"__codelineno-1-1\" name=\"__codelineno-1-1\" href=\"#__codelineno-1-1\"></a>orchard<span class=\"w\"> </span>ssh<span class=\"w\"> </span>vm<span class=\"w\"> </span>sonoma-builder<span class=\"w\"> </span><span class=\"s1\">&#39;sh -s&#39;</span><span class=\"w\"> </span>&lt;<span class=\"w\"> </span>script.sh\n</code></pre></div>\n<h3 id=\"orchard-vnc\"><code>orchard vnc</code><a class=\"headerlink\" href=\"#orchard-vnc\" title=\"Permanent link\">&para;</a></h3>\n<p>Establishes a port forwarding to the specified VM\u2019s default VNC port <code>5900</code> and opens the default macOS Screen Sharing app.</p>\n<p>For example, <code>orchard vnc vm sonoma-builder</code> will establish a port-forwarding to the <code>ventura-builder</code> VM's port <code>5900</code> under the hood and launch macOS Screen Sharing app.</p>\n<p>Note that the SSH and VNC commands expect the VM resource to specify credentials in it\u2019s definition (can be done via <code>orchard create vm</code>),  and will otherwise fall back to the credentials specified by <code>--username</code> and <code>--password</code>, or if none specified \u2014 to de-facto standard of <code>admin:admin</code> credentials.</p>\n<h2 id=\"conclusion\">Conclusion<a class=\"headerlink\" href=\"#conclusion\" title=\"Permanent link\">&para;</a></h2>\n<p>Overall, the technology described in this article somewhat resembles what <a href=\"https://cirrus-ci.org/blog/2021/08/06/introducing-cirrus-terminal-a-simple-way-to-get-ssh-like-access-to-your-tasks/\">we previously did for Cirrus Terminal</a>. The only difference is that in Cirrus Terminal we carry terminal-specific characters, and in Orchard \u2014 we carry bytes for an arbitrary TCP connection.</p>\n<p>We really hope this feature will be useful for many, just as the Cirrus Terminal, and that it will remove the pain of scaling Tart beyond a single machine.</p>\n<p>You can give <a href=\"https://github.com/cirruslabs/orchard\">Orchard</a> a try by running it locally in development mode on any Apple Silicon device:</p>\n<div class=\"highlight\"><pre><span></span><code><a id=\"__codelineno-2-1\" name=\"__codelineno-2-1\" href=\"#__codelineno-2-1\"></a>brew<span class=\"w\"> </span>install<span class=\"w\"> </span>cirruslabs/cli/orchard\n<a id=\"__codelineno-2-2\" name=\"__codelineno-2-2\" href=\"#__codelineno-2-2\"></a>orchard<span class=\"w\"> </span>dev\n</code></pre></div>\n<p>This will launch a development cluster with a single worker on your machine. Refer to <a href=\"https://github.com/cirruslabs/orchard#creating-virtual-machines\">Orchard documentation</a>\non how to create your first virtual machine and access it.</p>\n<p>Stay tuned and don\u2019t hesitate to send us your feedback either <a href=\"https://github.com/cirruslabs/orchard\">on GitHub</a>\u00a0or\u00a0<a href=\"https://twitter.com/cirrus_labs\">Twitter</a>!</p>", "image": "https://tart.run/assets/images/social/blog/2023/04/28/ssh-over-grpc-or-how-orchard-simplifies-accessing-vms-in-private-networks.png", "date_modified": "2025-09-22T20:02:39+00:00", "date_published": "2023-04-28T00:00:00+00:00", "authors": [{"name": "Nikolay Edigaryev"}], "tags": null}, {"id": "https://tart.run/blog/2023/09/20/tart-200-and-community-updates/", "url": "https://tart.run/blog/2023/09/20/tart-200-and-community-updates/", "title": "Tart 2.0.0 and community updates", "content_html": "<h1 id=\"tart-200-and-community-updates\">Tart 2.0.0 and community updates<a class=\"headerlink\" href=\"#tart-200-and-community-updates\" title=\"Permanent link\">&para;</a></h1>\n<p>Today we'd like to share some news and updates around the Tart ecosystem since the Tart 1.0.0 release back in February.</p>\n<!-- more -->\n\n<h2 id=\"community-growth\">Community Growth<a class=\"headerlink\" href=\"#community-growth\" title=\"Permanent link\">&para;</a></h2>\n<p>In the last 7 months Tart community almost tripled and growth is continuing to accelerate. Tart just crossed 25,000 installations,\ndozens of companies that we know of are using Tart in their daily workflows. If your company is not in the list please consider\n<a href=\"https://github.com/cirruslabs/tart/blob/main/Resources/Users/HowToAddYourself.md\">joining</a>!</p>\n<div class=\"grid cards\">\n<ul>\n<li><img alt=\"\" height=\"65\" src=\"https://github.com/cirruslabs/tart/raw/main/Resources/Users/Krisp.png\" /></li>\n<li><img alt=\"\" height=\"65\" src=\"https://github.com/cirruslabs/tart/raw/main/Resources/Users/Mullvad.png\" /></li>\n<li><img alt=\"\" height=\"65\" src=\"https://github.com/cirruslabs/tart/raw/main/Resources/Users/ahrefs.png\" /></li>\n<li><img alt=\"\" height=\"65\" src=\"https://github.com/cirruslabs/tart/raw/main/Resources/Users/Suran.png\" /></li>\n<li><img alt=\"\" height=\"65\" src=\"https://github.com/cirruslabs/tart/raw/main/Resources/Users/Symflower.png\" /></li>\n<li><img alt=\"\" height=\"65\" src=\"https://github.com/cirruslabs/tart/raw/main/Resources/Users/Transloadit.png\" /></li>\n<li><img alt=\"\" height=\"65\" src=\"https://github.com/cirruslabs/tart/raw/main/Resources/Users/PITSGlobalDataRecoveryServices.png\" /></li>\n<li><img alt=\"\" height=\"65\" src=\"https://github.com/cirruslabs/tart/raw/main/Resources/Users/Uphold.png\" /></li>\n</ul>\n</div>\n<p>We are also very pleased by how the community responded to <a href=\"../../../02/11/changing-tart-license/\">the license change</a>.\nWe now have a number of companies running Tart at scale under the new license. Revenue from the licensing allowed us to\nallocate time to continue improving Tart which brings us to the section below.</p>\n<h2 id=\"recent-updates-and-whats-changing-in-tart-200\">Recent updates and what's changing in Tart 2.0.0<a class=\"headerlink\" href=\"#recent-updates-and-whats-changing-in-tart-200\" title=\"Permanent link\">&para;</a></h2>\n<p>In the last 7 months we've had 12 feature releases that brought a lot of features requested by the community. Here are just\na few of them to highlight:</p>\n<p>-<a href=\"../../../../../integrations/gitlab-runner/\">Custom GitLab Runner Executor</a>.\n-<a href=\"../../../04/25/announcing-orchard-orchestration-for-managing-macos-virtual-machines-at-scale/\">Cluster Management via Orchard</a>.\n-Numerous compatibility improvements for all kinds of OCI-registries.\n-Sonoma Support (see details <a href=\"#macos-sonoma-updates\">below</a>).</p>\n<p>But one of the most requested features/complaints was around pulling huge Tart images from remote OCI-compatible registries.\nWith an ideal network conditions <code>tart pull</code> worked pretty good but in case of any network issues it was required to\nrestart the pull from scratch. Additionally, some registries are notably slow streaming a single blob but can stream\nmultiple blobs in parallel. Finally, the initial format of storing Tart VMs was very naive: disk image is compressed\nvia a single stream which is chunked up into blobs that are serially uploaded to a registry. A single compression stream\nmeans that Tart can also only decompress blobs serially.</p>\n<p>Given these three observations above we came up with an improved format of storing Tart VM disk images. In Tart 2.0.0\ndisk images are chunked up first and compressed independently into blobs, when pushed, each blob has attached annotations\nof expected uncompressed size and a checksum. This way when Tart 2.0.0 is pulling an image pushed by Tart 2.0.0 each blob can\nbe pulled, uncompressed and written at the right offset independently. Having checksums along expected uncompressed blob size\nalso allowed to support resumable pulls. Upon a failure Tart 2.0.0 will compare checksums of chunks and will continue pulling\nonly missing blobs.</p>\n<p>Overall in our experiments we saw a 10% improvement in compressed size of the images and <strong>4 times faster pulls</strong>.</p>\n<p>In order to try the new image format please upgrade Tart and try to pull any of <a href=\"https://github.com/orgs/cirruslabs/packages?tab=packages&amp;q=macos-sonoma\">the Sonoma images</a>:</p>\n<div class=\"highlight\"><pre><span></span><code><a id=\"__codelineno-0-1\" name=\"__codelineno-0-1\" href=\"#__codelineno-0-1\"></a>brew<span class=\"w\"> </span>upgrade<span class=\"w\"> </span>cirruslabs/cli/tart\n<a id=\"__codelineno-0-2\" name=\"__codelineno-0-2\" href=\"#__codelineno-0-2\"></a>tart<span class=\"w\"> </span>pull<span class=\"w\"> </span>ghcr.io/cirruslabs/macos-sonoma-base:latest\n</code></pre></div>\n<h2 id=\"macos-sonoma-updates\">macOS Sonoma Updates<a class=\"headerlink\" href=\"#macos-sonoma-updates\" title=\"Permanent link\">&para;</a></h2>\n<p>Tart VMs now can be run in a \"suspendable\" mode which will enable VM snapshotting instead of the standard shutdown.\nVMs with an existing snapshot will <code>run</code> from the same state as they got snapshotted. Please check demo down below:</p>\n<div>\n    <blockquote class=\"twitter-tweet\" data-theme=\"dark\">\n      <p lang=\"en\" dir=\"ltr\">\n        Tart 1.8.0 brings macOS Sonoma updates! \ud83c\udf4f Now you can suspend and resume your virtual machines for even faster startup times. Check out the demo below \ud83d\udc47 <a href=\"https://t.co/RoRFT8Nwst\">pic.twitter.com/RoRFT8Nwst</a>\n      </p>&mdash; Cirrus Labs (@cirrus_labs) <a href=\"https://twitter.com/cirrus_labs/status/1677308360385765382?ref_src=twsrc%5Etfw\">July 7, 2023</a>\n    </blockquote> \n    <script src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</div>\n\n<p>There are two caveats to the \"suspendable\" mode support:</p>\n<ol>\n<li>Both host and guest should be running macOS Sonoma.</li>\n<li>Snapshots are locally encrypted and can't be shared between physical hosts. Therefore <code>tart push</code> won't push the corresponding snapshotted state of the VM.</li>\n</ol>\n<p>Try the \"suspendable\" mode for yourself by passing <code>--suspendable</code> flag to a <code>tart run</code> command:</p>\n<div class=\"highlight\"><pre><span></span><code><a id=\"__codelineno-1-1\" name=\"__codelineno-1-1\" href=\"#__codelineno-1-1\"></a>tart<span class=\"w\"> </span>clone<span class=\"w\"> </span>ghcr.io/cirruslabs/macos-sonoma-base:latest<span class=\"w\"> </span>sonoma-base\n<a id=\"__codelineno-1-2\" name=\"__codelineno-1-2\" href=\"#__codelineno-1-2\"></a>tart<span class=\"w\"> </span>run<span class=\"w\"> </span>--suspendable<span class=\"w\"> </span>sonoma-base\n</code></pre></div>\n<h2 id=\"conclusion\">Conclusion<a class=\"headerlink\" href=\"#conclusion\" title=\"Permanent link\">&para;</a></h2>\n<p>We are very excited about this major release of Tart. Please give it a try and let us know how it went!</p>\n<p>Stay tuned for new updates and announcements! There are a few coming up very shortly...</p>", "image": "https://tart.run/assets/images/social/blog/2023/09/20/tart-200-and-community-updates.png", "date_modified": "2025-09-22T20:02:39+00:00", "date_published": "2023-09-20T00:00:00+00:00", "authors": [{"name": "Fedor Korotkov"}], "tags": null}, {"id": "https://tart.run/blog/2023/10/06/tart-is-now-available-on-aws-marketplace/", "url": "https://tart.run/blog/2023/10/06/tart-is-now-available-on-aws-marketplace/", "title": "Tart is now available on AWS Marketplace", "content_html": "<h1 id=\"tart-is-now-available-on-aws-marketplace\">Tart is now available on AWS Marketplace<a class=\"headerlink\" href=\"#tart-is-now-available-on-aws-marketplace\" title=\"Permanent link\">&para;</a></h1>\n<p>Announcing <a href=\"https://aws.amazon.com/marketplace/pp/prodview-qczco34wlkdws\">official AMIs for EC2 Mac Instances</a>\nwith preconfigured Tart installation that is optimized to work within AWS infrastructure.</p>\n<p>EC2 Mac Instances is a gem of engineering powered by AWS Nitro devices. Just imagine there is a physical Mac Mini with\na plugged in Nitro device that can push the physical power button!</p>\n<p><img alt=\"EC2 M2 Pro\" src=\"../../../../images/ec2-mac2-m2pro.png\" /></p>\n<p>This clever synergy between Apple Hardware and Nitro System allows seamless integration with VPC networking and booting macOS from an EBS volume.</p>\n<p>In this blog post we\u2019ll see how a virtualization solution like Tart can compliment and elevate experience with EC2 Mac Instances.</p>\n<!-- more -->\n\n<p>Let\u2019s start from the basics, what EC2 Mac Instances allow to do compared to physical Mac Minis seating in offices of\nmany companies around the world?</p>\n<p>First and foremost, EC2 Mac Instances sit inside AWS data centers and can leverage all the goodies of VPC networking\nwithin your company's existing infrastructure. No need to connect your Macs in the office through a VPN and deal\nwith networking and security.</p>\n<p>Additionally, EC2 Mac Instances are booting from EBS volumes which means it is possible to always have reproducible instances\nand apply all the best practices of Infrastructure-as-Code. Managing a fleet of physical Macs is a pain and it's very hard\nto make them configured in a reproducible and stable way. With booting from identical EBS volumes your team is always sure\nabout the identical initial state of the fleet.</p>\n<h2 id=\"compromises-of-ec2-mac-instances\">Compromises of EC2 Mac Instances<a class=\"headerlink\" href=\"#compromises-of-ec2-mac-instances\" title=\"Permanent link\">&para;</a></h2>\n<p>The flexibility of EBS volumes for macOS comes with some compromises that virtualization solutions like Tart can help with.\nThe initial boot from an EBS volume takes some time and not instant. macOS itself is pretty heavy and a Nitro device needs\nto download tens of gigabytes that macOS requires in order to boot. This means that <strong>resetting a EC2 Mac Instance to a clean state\nis not instant and usually takes a couple of minutes</strong> when you can\u2019t utilize the precious resources for your workloads.</p>\n<p>It is much easier to tailor such EBS volumes with tools like Packer but there is still a <strong>friction to test newly created EBS volumes</strong>\nsince one needs to start and run a EC2 Mac Instance and it\u2019s not possible to test things locally. Similarly it is even harder\nto test beta versions of macOS that require manual interaction with a running instance.</p>\n<h2 id=\"solution\">Solution<a class=\"headerlink\" href=\"#solution\" title=\"Permanent link\">&para;</a></h2>\n<p>Tart can help with all the compromises! Tart virtual machines (VMs) have nearly native performance thanks to utilizing\nnative <code>Virtualization.Framework</code> that was developed along the first Apple Silicon chip. <strong>Tart VMs can be copied/disposed\ninstantly and booting a fresh Tart VM takes only several seconds</strong>. It is also possible to run two different Tart VMs in parallel\nthat can have completely different versions of macOS and packages. For example, it is possible to have the latest stable macOS\nwith the release version of Xcode along with the next version of macOS with the latest beta of Xcode.</p>\n<p>Creation of Tart VMs can be automated with <a href=\"https://github.com/cirruslabs/packer-plugin-tart\">a Packer plugin</a> the same way as\ncreation of EC2 AMIs with one caveat that <strong>Tart Packer Plugin works locally so you can test the same virtual machine locally\nas you would run it in the cloud</strong>.</p>\n<p>Lightweight nature of Tart VMs with a focus on an easy-to-integrate Tart CLI compliments any macOS automation and helps to reduce\nthe feedback cycle and improves reproducibility of macOS environments even further.</p>\n<h2 id=\"conclusion\">Conclusion<a class=\"headerlink\" href=\"#conclusion\" title=\"Permanent link\">&para;</a></h2>\n<p>We are excited to bring <a href=\"https://aws.amazon.com/marketplace/pp/prodview-qczco34wlkdws\">official AMIs that include Tart installation optimized to work within AWS</a>.\nIn the coming weeks when macOS Sonoma will become available on AWS we\u2019ll release another update specifically targeting EC2 Mac Instances. \nThis update will simplify access to local SSDs of Mac Instances that are slightly faster than EBS volumes. Stay tuned and don\u2019t hesitate\nto ask any <a href=\"https://tart.run/licensing/\">questions</a>.</p>", "image": "https://tart.run/assets/images/social/blog/2023/10/06/tart-is-now-available-on-aws-marketplace.png", "date_modified": "2025-09-22T20:02:39+00:00", "date_published": "2023-10-06T00:00:00+00:00", "authors": [{"name": "Fedor Korotkov"}], "tags": null}, {"id": "https://tart.run/blog/2023/11/03/new-dashboard-with-insights-into-performance-of-cirrus-runners/", "url": "https://tart.run/blog/2023/11/03/new-dashboard-with-insights-into-performance-of-cirrus-runners/", "title": "New dashboard with insights into performance of Cirrus Runners", "content_html": "<h1 id=\"new-dashboard-with-insights-into-performance-of-cirrus-runners\">New dashboard with insights into performance of Cirrus Runners<a class=\"headerlink\" href=\"#new-dashboard-with-insights-into-performance-of-cirrus-runners\" title=\"Permanent link\">&para;</a></h1>\n<p>This month we are celebrating one year since launching Cirrus Runners \u2014 managed Apple Silicon infrastructure for your\nGitHub Actions. During the last 12 months we ran millions of workflows for our customers and now ready to share some insights\ninto price performance of them for our customers.</p>\n<p>One of the key difference with Cirrus Runners is how they are getting billed for. Customers purchase Cirrus Runners via monthly subscription\nthat costs $150 per each Cirrus Runner. Each runner can be used 24 hours a day 7 days a week to run GitHub Actions workflows\nfor an organization. If there are more outstanding jobs than available runners then they are queued and executed as soon as\nthere is a free runner. This is different from how GitHub-managed GitHub Actions are billed for \u2014 you pay for each minute of execution time.</p>\n<p>The benefit of a fixed price is that you can run as many jobs as you want without worrying about the cost. The downside is that\nyou need to make sure that you are using your runners efficiently. This is where the new dashboard comes in handy.</p>\n<!-- more -->\n\n<p>But first, <strong>let's see theoretically the lowest price per minute</strong> of a Cirrus Runners. If you run 24 hours a day 7 days a week\nthen you will get 43,200 minutes of execution time per month. This means that the price per minute is $0.0035 if your runners\nutilization is 100%. But even if your engineering teams is located in a single time zone and works 8 hours a day 5 days a week\nthen you will get 9,600 minutes of execution time per month which comes down to $0.015 per-minute. This is still more than 10 times cheaper\nthan recently announced Apple Silicon GitHub-manged runners that cost $0.16 per minute.</p>\n<p>Now lets take a look at the new Cirrus Runners dashboard of a real customers that run their workflows on Cirrus Runners\nand <strong>practically pushing the price performance pretty close to the theoretical minimum</strong>.</p>\n<p><img alt=\"Cirrus Runners Dashboard\" src=\"../../../../images/runners-price-performance-2.png\" /></p>\n<p>As you can see above Cirrus Runners Dashboard focuses on 4 core metrics:</p>\n<ol>\n<li><strong>Minutes Used</strong> \u2014 overall amount of minutes that Cirrus Runners were executing jobs.</li>\n<li><strong>Workflow Runs</strong> \u2014 absolute number of workflow runs that were executed on Cirrus Runners.</li>\n<li><strong>Queue Size</strong> \u2014 number of jobs that were queued and waiting for a free Cirrus Runner.</li>\n<li><strong>Queue Time</strong> \u2014 average time that jobs were waiting in the queue.</li>\n</ol>\n<p>In this particular example price performance of Cirrus Runners is $0.006 per minute which is 2 times more than the theoretical minimum\nand <strong>26 times better than GitHub-managed Apple Silicon runners</strong>. But this is a extreme example, looking at queue time and queue size\nwe can see that the downside of such great price performance is that jobs are waiting in the queue on average around 5 minutes.</p>\n<p>Here is another example of Cirrus Runners Dashboard for a different customer that has a slightly higher price performance of $0.017 per minute\nbut at the same time doesn't experience queue time at all. <strong>Note that $0.017 is still 10 times cheaper than GitHub-managed Apple Silicon runners</strong>.</p>\n<p><img alt=\"Cirrus Runners Dashboard\" src=\"../../../../images/runners-price-performance-3.png\" /></p>\n<h2 id=\"conclusion\">Conclusion<a class=\"headerlink\" href=\"#conclusion\" title=\"Permanent link\">&para;</a></h2>\n<p>Having a fixed price for Cirrus Runners is a great way to save money on your CI/CD infrastructure and just in general have predictable budged.\nBut it requires keeping the balance between price per minute and queue time. Cirrus Runners Dashboard helps you to keep an eye on this balance\nand make sure that you are getting the most out of your Cirrus Runners.</p>", "image": "https://tart.run/assets/images/social/blog/2023/11/03/new-dashboard-with-insights-into-performance-of-cirrus-runners.png", "date_modified": "2025-09-22T20:02:39+00:00", "date_published": "2023-11-03T00:00:00+00:00", "authors": [{"name": "Fedor Korotkov"}], "tags": null}, {"id": "https://tart.run/blog/2025/06/01/bridging-the-gaps-with-the-tart-guest-agent/", "url": "https://tart.run/blog/2025/06/01/bridging-the-gaps-with-the-tart-guest-agent/", "title": "Bridging the gaps with the Tart Guest Agent", "content_html": "<h1 id=\"bridging-the-gaps-with-the-tart-guest-agent\">Bridging the gaps with the Tart Guest Agent<a class=\"headerlink\" href=\"#bridging-the-gaps-with-the-tart-guest-agent\" title=\"Permanent link\">&para;</a></h1>\n<p>We're introducing a new improvement for the Tart usability experience: a <a href=\"https://github.com/cirruslabs/tart-guest-agent\">Tart Guest Agent</a>.</p>\n<p>This agent provides automatic disk resizing, seamless clipboard sharing for macOS guests (a <a href=\"https://github.com/cirruslabs/tart/issues/14\">long-awaited</a> feature), and the ability to run commands, without SSH and networking, using the new <code>tart exec</code> command.</p>\n<p>As of recently, we include this agent in all non-vanilla Cirrus Labs images, so you likely won't need to do anything to benefit from these usability improvements.</p>\n<p>Read on to learn why we chose to implement the agent from scratch in Golang, and which features we plan to add next.</p>\n<!-- more -->\n\n<h2 id=\"existing-solutions\">Existing solutions<a class=\"headerlink\" href=\"#existing-solutions\" title=\"Permanent link\">&para;</a></h2>\n<p>Tart uses the Virtualization.Framework, and the latter implemented a SPICE client some time ago, however, one piece was missing: the agent that runs inside the guest.</p>\n<p>The original <a href=\"https://gitlab.freedesktop.org/spice/linux/vd_agent\">SPICE <code>vdagent</code> implementation</a> only supports Linux. While <a href=\"https://github.com/utmapp/vd_agent\">a fork</a> from the UTM project adds macOS support, the long-term viability of maintaining this fork without upstreaming changes is uncertain.</p>\n<p>Moreover, if we were to add some extra functionality (as we did), there would be more than one agent binary to ship and install, which complicates maintenance and makes it harder to explain to users why we need a bunch of agent binaries.</p>\n<p>In the end, we decided to go with our own solution, one that would easily accomodate future ideas.</p>\n<h2 id=\"rolling-our-own-agent\">Rolling our own agent<a class=\"headerlink\" href=\"#rolling-our-own-agent\" title=\"Permanent link\">&para;</a></h2>\n<p>After carefully inspecting the <a href=\"https://www.spice-space.org/agent-protocol.html\"><code>vdagent</code> protocol</a> we've realized that the clipboard sharing is actually a small subset of the whole protocol, making it relatively simple to implement.</p>\n<p>Thanks to Golang, we were able to implement the protocol much faster than we could have with a lower-level language like C (with all due respect), which requires manual memory management and complex event loops.</p>\n<p>As for the command execution via <code>tart exec</code>, we've decided to go with gRPC with a rather simple protocol:</p>\n<p><img alt=\"An visualization of gRPC protocol used by the Tart Guest Agent\" src=\"../../../../images/tart-guest-agent-grpc-protocol.png\" /></p>\n<p>For each <code>tart exec</code> invocation a new gRPC <code>Exec</code> bidirectional stream is established with the agent running inside a VM. After the gRPC stream is established, <code>tart exec</code> sends a command to execute to the guest and streams the I/O. Once the command terminates, <code>tart exec</code> collects the process exit code and quits with exactly that exit code.</p>\n<p>Using gRPC simplifies <code>tart exec</code> implementation because of code generation and forms a nice bridge between the host and the guest which allows us to easily expand the protocol later down the road when we decide to introduce new features.</p>\n<p>Thanks to <a href=\"https://github.com/grpc/grpc-swift\">gRPC Swift</a>, which is built on top of <a href=\"https://github.com/apple/swift-nio\">SwiftNIO</a>, we get <a href=\"https://docs.swift.org/swift-book/documentation/the-swift-programming-language/concurrency/\"><code>async/await</code></a> support for free, further simplifying the <code>tart exec</code> logic.</p>\n<p>As for the Tart Guest Agent, the final result is a Golang binary that <a href=\"https://github.com/cirruslabs/tart-guest-agent?tab=readme-ov-file#guest-agent-for-tart-vms\">can be customized</a> depending on the execution context:</p>\n<ul>\n<li>launchd global daemon \u2014 runs as a privileged user (<code>root</code>), has no clipboard access<ul>\n<li><code>--resize-disk</code> \u2014 resizes the disk when there's a free space at the end of a disk (assuming that one previously ran <code>tart set --disk-size</code>)</li>\n</ul>\n</li>\n<li>launchd global agent \u2014 runs as a normal user (<code>admin</code>), has clipboard access<ul>\n<li><code>--run-vdagent</code> \u2014 clipboard sharing</li>\n<li><code>--run-rpc</code> \u2014 <code>tart exec</code> and new functionality in the future</li>\n</ul>\n</li>\n</ul>\n<p>We\u2019ve also introduced <code>--run-daemon</code> (which implies <code>--resize-disk</code>) and <code>--run-agent</code> (which implies both <code>--run-vdagent</code> and <code>--run-rpc</code>) to help run the most appropriate functionality based on the given context.</p>\n<h2 id=\"future-plans\">Future plans<a class=\"headerlink\" href=\"#future-plans\" title=\"Permanent link\">&para;</a></h2>\n<p>First, we'd like to thank our paid clients, without whom this feature wouldn't have been possible.</p>\n<p><a href=\"../../../../../licensing/\">Become one now</a> and enjoy higher allowances for Tart VMs and Orchard workers\u2014while helping ensure that our roadmap aligns with your company's needs.</p>\n<p>In the near future we plan to implement:</p>\n<ul>\n<li>Linux support \u2014 to provide seamless experience for Linux guests too</li>\n<li>a new <code>tart ip</code> resolver \u2014 to provide a more robust IP retrieval facility for Linux guests, which often struggle to populate the host's ARP table with their network activity</li>\n<li><code>tart cp</code> command \u2014 to copy files from/to guest VMs</li>\n</ul>\n<p>Stay tuned, and feel free to send us feedback on <a href=\"https://github.com/cirruslabs/tart\">GitHub</a> and <a href=\"https://x.com/cirrus_labs\">Twitter</a>!</p>", "image": "https://tart.run/assets/images/social/blog/2025/06/01/bridging-the-gaps-with-the-tart-guest-agent.png", "date_modified": "2025-06-01T23:54:45+00:00", "date_published": "2025-06-01T00:00:00+00:00", "authors": [{"name": "Nikolay Edigaryev"}], "tags": null}, {"id": "https://tart.run/blog/2024/06/20/jumping-through-the-hoops-ssh-jump-host-functionality-in-orchard/", "url": "https://tart.run/blog/2024/06/20/jumping-through-the-hoops-ssh-jump-host-functionality-in-orchard/", "title": "Jumping through the hoops: SSH jump host functionality in Orchard", "content_html": "<h1 id=\"jumping-through-the-hoops-ssh-jump-host-functionality-in-orchard\">Jumping through the hoops: SSH jump host functionality in Orchard<a class=\"headerlink\" href=\"#jumping-through-the-hoops-ssh-jump-host-functionality-in-orchard\" title=\"Permanent link\">&para;</a></h1>\n<p>Almost a year ago, when we started building <a href=\"https://github.com/cirruslabs/orchard\">Orchard</a>, an orchestration system for Tart, we quickly realized that most worker machines will be in a private network, and that VMs will be only reachable from the worker machines themselves. Thus, one of our goals became to simplify accessing the compute resources in a cluster through a centralized controller host.</p>\n<p>This effort resulted in commands like <code>orchard port-forward</code> and <code>orchard ssh</code>, which were later improved to support connecting not just to the VMs, but to the worker machines themselves.</p>\n<p>Today, we\u2019re making an even further step in this effort: with a trivial configuration, an Orchard controller can act as an SSH jump host to allow connecting to the VMs using just the <code>ssh</code> command like <code>ssh -J &lt;service account name&gt;@orchard-controller.example.com &lt;VM name&gt;</code>!</p>\n<!-- more -->\n\n<h2 id=\"implementation\">Implementation<a class=\"headerlink\" href=\"#implementation\" title=\"Permanent link\">&para;</a></h2>\n<p>In a typical cluster there\u2019s one controller, to which workers connect by calling various REST API endpoints to synchronize the worker &amp; VMs state. Each worker also maintains a persistent bi-directional gRPC connection with the controller, with the goal of improving the overall reactivity and making the port-forwarding work.</p>\n<p>The gRPC service definition that the controller offers is pretty minimalistic:</p>\n<div class=\"highlight\"><pre><span></span><code><a id=\"__codelineno-0-1\" name=\"__codelineno-0-1\" href=\"#__codelineno-0-1\"></a><span class=\"kd\">service</span><span class=\"w\"> </span><span class=\"n\">Controller</span><span class=\"w\"> </span><span class=\"p\">{</span>\n<a id=\"__codelineno-0-2\" name=\"__codelineno-0-2\" href=\"#__codelineno-0-2\"></a><span class=\"w\">  </span><span class=\"k\">rpc</span><span class=\"w\"> </span><span class=\"n\">Watch</span><span class=\"p\">(</span><span class=\"n\">google.protobuf.Empty</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"k\">returns</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"n\">stream</span><span class=\"w\"> </span><span class=\"n\">WatchInstruction</span><span class=\"p\">);</span>\n<a id=\"__codelineno-0-3\" name=\"__codelineno-0-3\" href=\"#__codelineno-0-3\"></a><span class=\"w\">  </span><span class=\"k\">rpc</span><span class=\"w\"> </span><span class=\"n\">PortForward</span><span class=\"p\">(</span><span class=\"n\">stream</span><span class=\"w\"> </span><span class=\"n\">PortForwardData</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"k\">returns</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"n\">stream</span><span class=\"w\"> </span><span class=\"n\">PortForwardData</span><span class=\"p\">);</span>\n<a id=\"__codelineno-0-4\" name=\"__codelineno-0-4\" href=\"#__codelineno-0-4\"></a><span class=\"p\">}</span>\n</code></pre></div>\n<p>Each watch instruction corresponds a single action to be done by the worker, which can either be a request for establishing a port-forwarding stream or a request for VMs re-syncing:</p>\n<div class=\"highlight\"><pre><span></span><code><a id=\"__codelineno-1-1\" name=\"__codelineno-1-1\" href=\"#__codelineno-1-1\"></a><span class=\"k\">oneof</span><span class=\"w\"> </span><span class=\"n\">action</span><span class=\"w\"> </span><span class=\"p\">{</span>\n<a id=\"__codelineno-1-2\" name=\"__codelineno-1-2\" href=\"#__codelineno-1-2\"></a><span class=\"w\">  </span><span class=\"n\">PortForward</span><span class=\"w\"> </span><span class=\"na\">port_forward_action</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"p\">;</span>\n<a id=\"__codelineno-1-3\" name=\"__codelineno-1-3\" href=\"#__codelineno-1-3\"></a><span class=\"w\">  </span><span class=\"n\">SyncVMs</span><span class=\"w\"> </span><span class=\"na\">sync_vms_action</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"p\">;</span>\n<a id=\"__codelineno-1-4\" name=\"__codelineno-1-4\" href=\"#__codelineno-1-4\"></a><span class=\"p\">}</span>\n</code></pre></div>\n<p>Now, when the user invokes <code>orchard port-forward</code> or <code>orchard ssh</code>, controller effectively becomes a rendezvous point by accepting the WebSocket connection from the user, and then asking the worker associated with the requested VM to establish a port-forwarding stream, and finally proxying the two streams together.</p>\n<p><img alt=\"An illustration showing the Orchard controller and worker proxying the SSH connection\" src=\"../../../../images/jumping-through-the-hoops.png\" /></p>\n<p>SSH protocol works the same way, multiplexing multiple channels in a single transport connection, where each channel can be upgraded either to an interactive session (that\u2019s what you get when you <code>ssh</code> to the server) or X11 channel (for X11 forwarding using <code>-X</code>), direct or forward TCP/IP channels (these are used for local and remote port-forwarding when using <code>-L</code> and <code>-R</code> options correspondingly) and so on.</p>\n<p>In fact, <code>ssh -J</code> jump host functionality also uses the direct TCP/IP channel, which is <a href=\"https://datatracker.ietf.org/doc/html/rfc4254#section-7.2\">just a single port-forwarding request</a> that needs to be implemented. We\u2019ve used <a href=\"https://pkg.go.dev/golang.org/x/crypto/ssh\">Golang's SSH library</a> as the most mature choice for this task, and it\u2019s been pleasant to work with so far.</p>\n<p>The support for <code>ssh -J</code> has landed in Orchard version 0.19.0. To configure the SSH jump host, simply add the <code>--listen-ssh</code> command-line argument to your <code>orchard controller run</code> invocation.</p>\n<p>Once running, you can connect to any VM in the cluster using the <code>ssh -J &lt;service account name&gt;@orchard-controller.example.com &lt;VM name&gt;</code>. The password for the jump host is the corresponding service account\u2019s token.</p>\n<h2 id=\"future-plans\">Future plans<a class=\"headerlink\" href=\"#future-plans\" title=\"Permanent link\">&para;</a></h2>\n<p>First of all, we\u2019d like to thank our paid clients, without which this feature wouldn\u2019t be possible. <a href=\"../../../../../licensing/\">Become one now</a> and get the benefit of higher Tart VMs and Orchard workers allowances and making sure that the roadmap for Tart and Orchard is aligned with your company's needs.</p>\n<p>In the near future we plan to implement a mechanism similar to <code>authorized_keys</code> file that will allow attaching public SSH keys to the Orchard controller\u2019s service accounts, and thus avoid the need to type the passwords.</p>\n<p>Stay tuned and don\u2019t hesitate to send us your feedback on <a href=\"https://github.com/cirruslabs/orchard\">GitHub</a> and <a href=\"https://x.com/cirrus_labs\">Twitter</a>!</p>", "image": "https://tart.run/assets/images/social/blog/2024/06/20/jumping-through-the-hoops-ssh-jump-host-functionality-in-orchard.png", "date_modified": "2024-06-20T22:39:41+00:00", "date_published": "2024-06-20T00:00:00+00:00", "authors": [{"name": "Nikolay Edigaryev"}], "tags": null}]}